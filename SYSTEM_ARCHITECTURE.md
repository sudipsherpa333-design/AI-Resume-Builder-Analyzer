# System Architecture — AI Resume Builder & Analyzer

## Overview
This document describes the system architecture, working mechanism, main algorithms, technology stack, data models, API contracts, security considerations, and an implementation roadmap for the AI Resume Builder & Analyzer project.

System Architecture Flow:

User Interface (React)
    ↓
Authentication Layer (JWT)
    ↓
API Gateway (Express.js)
    ↓
    ├─→ User Controller → MongoDB (Users Collection)
    ├─→ Resume Controller → MongoDB (Resumes Collection)
    ├─→ AI Module → OpenAI API → Analysis Results
    └─→ PDF Generator → Downloadable File

---

## Working Mechanism
1. User Registration / Login
   - User registers or logs in via the React UI.
   - Passwords are hashed with bcrypt before storage.
   - On successful auth, the server issues a signed JWT which the frontend stores (usually in localStorage or an httpOnly cookie depending on chosen strategy).
   - JWT is sent with API requests in the Authorization header: `Authorization: Bearer <token>`.

2. Resume Creation
   - User fills structured forms (personal info, experience, education, skills).
   - Frontend performs client-side validation (yup / custom validators).
   - Backend validates / sanitizes and stores resumes in the `resumes` collection with a reference to the owning user.
   - Real-time preview is generated by rendering stored form data into the selected template in the browser.

3. AI Analysis
   - When user requests analysis, relevant resume fields are packaged into a prompt and sent to OpenAI (or other chosen model).
   - AI provides: professional summary, bullet rewriting, keywords, and improvement suggestions.
   - Extracted keywords and ATS-relevant signals are calculated and stored with the analysis record.
   - Optionally cache analysis results to reduce repeated OpenAI usage for identical content.

4. Resume Management
   - Support multiple versions per user; each resume document stores metadata (createdAt, updatedAt, template, version).
   - Provide update and template-switch endpoints on the server.
   - Track version history: store diffs or snapshot copies for each save.

5. Export
   - Provide an endpoint or frontend flow to render a resume into a PDF.
   - Options: client-side PDF libraries (jsPDF/html2canvas) or server-side rendering using Puppeteer (Chromium) for pixel-perfect layout.
   - Return a file download to the user.

---

## Major Algorithms
- NLP via OpenAI GPT: content analysis, summary generation, and keyword extraction.
- ATS Score Algorithm: weighted scoring across metrics:
  - Required sections present (contact, experience, education, skills): weight 30%
  - Keywords match to target job description: weight 25%
  - Readability and grammar/conciseness: weight 20%
  - Formatting / order and template compatibility: weight 15%
  - Length and density: weight 10%

- Template Rendering: dynamic injection of user fields into HTML/CSS templates. For server-side PDFs use headless Chromium to render the HTML (Puppeteer) and produce a PDF.
- JWT Authentication: sign tokens with secret / private key and set suitable expiry (e.g., 7d) and refresh policy.
- Data Validation: employ both client-side validation (yup/formik) and server-side `express-validator` and sanitization.

---

## Technology Stack
- Frontend: React + Vite, React Router, Context API/Redux (for auth), Tailwind CSS for styling.
- Backend: Node.js, Express.js, Mongoose (MongoDB), JWT, bcrypt.
- Database: MongoDB (Atlas or self-hosted).
- AI Integration: OpenAI (GPT-4/3.5) via official OpenAI API.
- PDF Generation: Puppeteer (server-side) for best fidelity; fallback to jsPDF/html2canvas client-side for light use.

---

## Data Models (suggested)

User (collection: users)
- _id: ObjectId
- name: String
- email: String (unique)
- passwordHash: String
- role: String (user, admin)
- createdAt, updatedAt
- isVerified: Boolean
- lastLogin: Date

Resume (collection: resumes)
- _id: ObjectId
- ownerId: ObjectId (ref -> users)
- title: String
- templateId: String
- sections: Object (structured data for experience, education, skills, etc.)
- analysis: Object (last ATS score, keywords, aiSummary)
- versions: [ { dataSnapshot, createdAt, note } ]
- createdAt, updatedAt

Analysis (collection: analyses) — optional
- _id: ObjectId
- resumeId: ObjectId
- userId: ObjectId
- aiSummary: String
- keywords: [String]
- atsScore: Number
- suggestions: [String]
- model: String
- createdAt

---

## API Contract (examples)

Auth
- POST /api/auth/register
  - body: { name, email, password }
  - 201: { success: true, data: { user, token } }
  - 400: validation errors

- POST /api/auth/login
  - body: { email, password }
  - 200: { success: true, data: { user, token } }
  - 401: invalid credentials

- POST /api/auth/demo
  - body: {}
  - 200: demo login success with token

Resume
- POST /api/resumes
  - auth required (Bearer token)
  - body: { title, templateId, sections }
  - 201: { success: true, data: resume }

- GET /api/resumes/:id
  - auth required, owner or admin
  - 200: { success: true, data: resume }

AI
- POST /api/ai/analyze
  - auth required
  - body: { resumeId } or { content }
  - 200: { success: true, data: { aiSummary, keywords, atsScore, suggestions } }

PDF
- POST /api/resumes/:id/export
  - auth required
  - body: { templateId, options }
  - 200: PDF binary response (application/pdf)

Errors
- Standard error schema: { success: false, message: 'Description', errors?: { field: 'reason' } }

---

## Security Considerations
- Use HTTPS in production and secure cookies if storing tokens in cookies.
- Prefer httpOnly cookies for refresh tokens; store short-lived access tokens in memory or secure storage.
- Rate limit AI endpoints to avoid excessive OpenAI costs.
- Sanitize all user input before sending to AI to avoid prompt injection risks.
- Rotate JWT secrets and use environment-managed secrets (Vault/Env management).

---

## Implementation Roadmap (high level)
1. Core auth and user model
2. Resume data model and CRUD endpoints
3. Frontend resume builder UI with real-time preview
4. AI analysis integration (OpenAI) and caching layer
5. Template rendering and PDF export
6. Versioning and resume management UI
7. Polishing: social logins, email verification, rate limits, analytics

---

## Deployment & Scaling Notes
- Host backend on Node-friendly platforms (AWS ECS, Heroku, DigitalOcean App Platform) or containerize with Docker.
- Use MongoDB Atlas for managed scaling.
- Separate AI/analysis worker to handle heavy OpenAI calls and queue jobs (e.g., RabbitMQ, BullMQ) to avoid blocking user requests.

---

## Next Steps / Developer Hints
- Add endpoints iteratively; start with auth and resume CRUD.
- Create unit tests for the ATS scoring algorithm and API contract tests (supertest/mocha or jest).
- Implement a queue worker for AI analysis if utilization or API cost grows.

---

If you want, I can also:
- Generate `API_CONTRACT.md` with full request/response examples and sample curl commands.
- Scaffold server controllers and route stubs for the endpoints listed above.
- Create Mongoose schema files for the suggested models.

